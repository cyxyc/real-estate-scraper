scraper, podobný: https://github.com/JirkaZelenka/Sreality 
bakalářka k API sreality: https://dspace.cvut.cz/bitstream/handle/10467/103384/F8-BP-2021-Malach-Ondrej-thesis.pdf?sequence=-1&isAllowed=y
        API call: https://www.sreality.cz/api/cs/v2/estates?category_main_cb=1&category_sub_cb=6|7&category_type_cb=1&locality_district_id=5001|5008&locality_region_id=10
        -kdybych chtěl tak můžu veškerý webscraping nahradit APInama: 1. API (nahoře) vezme seznam všech vyfiltrovaných nemovitostí, vrátí základní údaje (ne všechyn detaily) + ID. To ID pak použiju do druhé API (dole) k získání detailů.
            -ale chci si nechat aspoň kus webscrapingu - na parádu

Imgur - IMGUR mozna NEPOTREBUJU  - teoreticky do PWBI můžu dávat rovnou URL obrázků z srealit a prevest je na Base64 (prevedou se na text a ulozi do reportu. ale to ho asi hodne zaseka)
https://github.com/Imgur/imgurpython
-udelat druhou SQL tabulku kde bude ID, stara URL (sreality), nova URL (imgur). jedno ID (nemovitost) bude mit vice fotek. (=nedelat to jako list) 
-abych mohl na imgur nahravat pod svuj acount a ne jako anonym, musim rucne inputovat pin :( to je hovadina. 


ML
-pridat k tomu i machine learning - CNN obrazkovou klasifikaci stavu nemovitosti (ruina --- novostavba). to pak vratit zpet do databaze a delat na tom predikci ceny nebo anomaly detekci
-jako DB pro uceni pouzit databazi srealit (maji tam  fotky + oznaceni novostavba atd. ej to nekdy v te tabulce. vytahnout to pres API (melo by to jit a byt jednodussi))
-databaze nemusi byt velka. jde spis o to si to vyzkouset. 

SCRAPER/ANALYTIKA
-trackovani stari inzeratu
-hledani podobnosti inzeratu (na zaklade treba vektoru similarity?)
-typ prodeje a typ nemovitosti dostat z Title z tabulky
-ta location co je v tabulce je nahovno - zkusit scrapnout jinak (možná z API jak ogithub typek?), popr zkusit dostat z odkazu nebo z location v tabulce, ale to pujde blbě. asi jen přes nějakou pomocnou tabulku se seznamem měst (protože tam jinak bude dělat bordel např. frýdek-místek - místek atd -> nepůjde to jen splitnout. podivat se na github jak to dělá borec)
    řešení: pomocná tabulka měst + tenhle script: 
    # Your DataFrame of sentences
    df_sentences = pd.DataFrame({'sentences': ["Hello, my name is John ", "I live in New York", "My friend's name is Jane Doe"]})

    # Your DataFrame of names
    df_names = pd.DataFrame({'names': ["John Doe", "Jane Doe", "Alice"]})

    # Convert names DataFrame to list
    names = df_names['names'].tolist()

    # Check if each sentence contains a name from the list and return the name
    df_sentences['name'] = df_sentences['sentences'].apply(lambda sentence: next((name for name in names if name in sentence), None))

    print(df_sentences)
-GIT týpek páruje lokality s tabulkou pomocí jejich souřadnic. podle mě by mohlo stačit to dělat podle názvu města tím scriptem nahoře

-lokalitu bych mohl brát ještě z GPS souřadnic ->  https://geocode.maps.co/ přes jejich API a na základě GPS mi řekne adresu (API call - limit 1 za sekundu! : https://geocode.maps.co/reverse?lat=49.734061604&lon=18.615677485&api_key=6603d5fe0cc3d866415536bwpb7a48d)
-nebo můžu použít geopy jak oborec z gitu: 
    from geopy.geocoders import Nominatim
    geolocator = Nominatim(timeout = 20, user_agent = "JZ_Sreality")
    latitude = 49.734061604
    longitude = 18.615677485
    location = geolocator.reverse([latitude, longitude])
    print(location.address)

-API má v sobě lepší informace. např o vlastnictví (ownership) (družstevní vs osobní!!!,), jak používat: https://www.sreality.cz/detail/prodej/byt/3+1/znojmo-znojmo-riegrova/405308748 => https://www.sreality.cz/api/cs/v2/estates/405308748
-pokud se nakoenc rozhodnu brát věci z API, tak scrapování detailů (fotky, cena, název, atd.) nedělej už přes browser ale z toho api. bude t mnohem rychlejší.
-v API je dobrá položka meta_description (krátké shrnutí. přidat do tabulky).
-podobnost inzerátů možná nedělat přes vektory ale přes GPS. nebo aspoň přidat GPS do tabulky ať to vektor líp najde. 


SQL databaze
-postgre SQL + pgAdmin 
    -ze zacatku lokalne, pak muzu dat do dockeru (bude vypadat dobre v portfoliu + k tomu mam kod z informatiky s Misom, akorat tak asi dodelat docker compose)







požadavky:
    garáže:
        -ukládat popisky, fotky, lokalitu, cenu
        -prodej i pronájem
        -nepotřebuju přesné detaily (vše vyčtu z popisku)
        -lokalita stačí vědět město
        -stáří inzerátu



ANALYTIKA:
pro power bi stačí aby DF mel URL v jedné buňce (v listu). když to rozjebu explodem na každý řádek zvlášť tak to pak nejde. ale musí to být ty imgur URL
a imgur zase vyžaduje aby to bylo explodnuté.
musím z toho co vyscrapuju udělat explode -> imgur -> zase zpátky (group by) -> power bi